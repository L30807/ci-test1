#!/usr/bin/env ruby
require 'timeout'
require 'shellwords'
require 'fileutils'
require 'yaml'
require 'uri'
require 'open3'
require 'logger'

class Casher
  include FileUtils

  CURL_FORMAT = <<-EOF
time_namelookup=%{time_namelookup}s time_connect=%{time_connect}s time_appconnect=%{time_appconnect}s time_pretransfer=%{time_pretransfer}s time_redirect=%{time_redirect}s time_starttransfer=%{time_starttransfer}s speed_download=%{speed_download}bytes/s time_total=%{time_total}s
EOF

  TAR_DIR_NOT_FOUND_REGEXP = /(\w+): Not found in archive/

  MD5DEEP_CHECK_LOG_LIMIT = 1000

  attr_reader :logger

  def initialize
    @casher_dir = ENV['CASHER_DIR'] || File.expand_path(".casher", ENV["HOME"])
    @mtime_file = File.expand_path('mtime.yml', @casher_dir)
    @checksum_file_before = File.expand_path('md5sums_before', @casher_dir)
    @checksum_file_after  = File.expand_path('md5sums_after', @casher_dir)
    @fetch_tar  = File.expand_path('fetch.tbz', @casher_dir)
    @push_tar   = File.expand_path('push.tbz', @casher_dir)
    @paths_file = File.expand_path('paths', @casher_dir)
    @mtimes     = File.exist?(@mtime_file) ? YAML.load_file(@mtime_file) : {}
    @timeout    = Integer(ENV['CASHER_TIME_OUT'] || 3*60)

    @logger = Logger.new(STDOUT)

    @logger.level = Logger.const_get((ENV['CASHER_LOG_LEVEL'] || 'info').upcase)
    if @logger.level == Logger::DEBUG
      File.open("#{@casher_dir}/curl_format", "w") { |f| f.write CURL_FORMAT }
      @tar_debug_flag = "-w @#{@casher_dir}/curl_format"
    end
    @logger.formatter = proc do |severity, datetime, progname, msg|
      "#{msg}\n"
    end

    @counter = 0

    mkdir_p @casher_dir
  end

  def run(command, *arguments)
    raise "unknown command" unless %w[fetch add push].include? command
    Timeout.timeout(@timeout) { send(command, *arguments) }
  rescue TimeoutError
    line  = "casher #{command}"
    line += Shellwords.join(arguments) if command == "add"
    logger.warn "running `#{line}` took longer than #{@timeout} seconds and has been aborted"
  end

  def fetch(*urls)
    logger.info "attempting to download cache archive"
    archive_found = false
    urls.each do |url|
      logger.info "fetching #{%r(([^/]+?/[^/]+?)(\?.*)?$).match(url)[1]}"

      @fetch_tar  = File.expand_path('fetch.tgz', @casher_dir) if path_ext(url) == 'tgz'

      if system "curl --tcp-nodelay #{@tar_debug_flag} %p -o %p -f -s --retry 3 2>&1 | tee #{@casher_dir}/fetch.log" % [url, @fetch_tar]
        puts # needs a newline here
        logger.info "found cache"
        archive_found = true
        break
      end
    end
    unless archive_found
      logger.info "could not download cache"
      if File.exist? @fetch_tar
        rm @fetch_tar
      end
    end
  end

  def add(*paths)
    expanded_paths = paths.map { |p| File.expand_path(p) }
    expanded_paths.map { |p| logger.info "adding #{p} to cache"; mkdir_p p }

    if fetched_archive
      output, errors = tar(:x, fetched_archive, *expanded_paths) do
        sleep 1
      end

      dirs_not_in_archive = errors.scan(TAR_DIR_NOT_FOUND_REGEXP).flatten.uniq

      dirs_not_in_archive.each do |dir|
        logger.info "#{dir} is not yet cached"
      end

      expanded_paths.map { |p| @mtimes[p] = Time.now.to_i }
    end

    if md5deep_available?
      File.open(@paths_file, 'a') { |f| f << expanded_paths.join("\n") << "\n" }
      system "md5deep -r #{expanded_paths.join(' ')} | sort >> #{@checksum_file_before}"
      logger.debug "Directories added: #{File.read(@paths_file)}"
    else
      File.open(@mtime_file, 'w') { |f| f << @mtimes.to_yaml }
      logger.debug "Directories added: #{File.read(@mtimes.keys)}"
    end

  end

  def push(url)
    unless changed?
      logger.info "nothing changed, not updating cache"
      return
    end

    logger.info "changes detected, packing new archive"

    @push_tar  = File.expand_path('push.tgz', @casher_dir) if path_ext(url) == 'tgz'

    tar(:c, @push_tar, *cached_directories) do
      @counter += 1
      STDOUT.write "." if @counter % 5 == 0
      sleep 1
    end

    logger.info "uploading archive"
    unless system "curl -T %p %p -s -S #{@tar_debug_flag} 2&>1 | tee #{@casher_dir}/push.log" % [@push_tar, url]
      puts # needs a newline here
      logger.warn "failed to upload cache", File.read("#{@casher_dir}/push.err.log"), File.read("#{@casher_dir}/push.log")
    end

  end

  def changed?
    return true unless fetched_archive

    if md5deep_available?
      paths  = File.read(@paths_file).gsub("\n", ' ')
      diff_file = File.expand_path('checksum_diff', @casher_dir)
      system("md5deep -r #{paths} | sort > #{@checksum_file_after}; diff -B #{@checksum_file_before} #{@checksum_file_after} | awk '/^[<>]/ {print $NF}' | sort > #{diff_file}")
      logger.debug("checksums before: #{File.read(@checksum_file_before)}")
      logger.debug("checksums after: #{File.read(@checksum_file_after)}")
      logger.debug("Diff file content: #{File.read(@diff_file)}")

      result = File.size(@checksum_file_before) == 0 || File.size(diff_file) > 0

      if File.size(diff_file) > 0
        first_bytes = File.read(diff_file, MD5DEEP_CHECK_LOG_LIMIT + 1)
        message = "change detected:\n#{first_bytes}\n"
        message << "...\n" if first_bytes.size > MD5DEEP_CHECK_LOG_LIMIT
        logger.info message
      end

      return result
    end

    @mtimes.any? do |path, mtime|
      Dir.glob("#{path}/**/*").any? do |file|
        next if File.mtime(file).to_i <= mtime
        next if File.directory?(file)
        logger.info "change detected: #{file}"
        true
      end
    end
  end

  def tar(flag, file, *args, &block)
    compression_flag = file.end_with?('.tbz') ? 'j' : 'z'

    cmd = "tar -P#{compression_flag}#{flag}f #{Shellwords.escape(file)} #{Shellwords.join(args)}"
    logger.debug "Exectuing command: #{cmd}"
    stdin, stdout, stderr, wait_thr = Open3.popen3(cmd)
    while wait_thr.status do
      yield
    end

    errors = stderr.read
    output = stdout.read
    File.write(File.join(@casher_dir, 'tar.log'), output)
    File.write(File.join(@casher_dir, 'tar.err.log'), errors)
    status = wait_thr.value

    if !status.success? && flag.to_s != 'x'
      logger.warn ["FAILED: #{cmd}", errors, output].join("\n")
    end

    [stdout, errors]
  end

  def path_ext(url)
    path = URI.split(url)[5]
    path.split('.').last
  end

  def fetched_archive
    [ File.expand_path('fetch.tbz', @casher_dir), File.expand_path('fetch.tgz', @casher_dir) ].find do |f|
      File.exist? f
    end
  end

  def md5deep_available?
    @md5deep_available ||= (system("which md5deep >/dev/null 2>&1").tap { |x| logger.debug("md5deep found on system") } || install_md5deep)
  end

  def install_md5deep
    if ENV['TRAVIS_OS_NAME'] == 'osx'
      system('brew install md5deep').tap { |x| logger.info "Successfully installed md5deep" }
    end
  end

  def cached_directories
    if File.exist?(@paths_file)
      File.read(@paths_file).split("\n").compact
    else
      @mtimes.keys
    end
  end
end

Casher.new.run(*ARGV) if $0 == __FILE__
